{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "654e5d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in c:\\users\\brhng\\anaconda3\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType , StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9f91d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"giveatry\").getOrCreate()\n",
    "\n",
    "df = spark.read.format('csv').options(delimiter=';',header=\"True\",inferschema=\"True\").load(\"C:\\\\Users\\\\brhng\\\\Desktop\\\\OnlineRetail.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eaf5dc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>541909</td>\n",
       "      <td>541909</td>\n",
       "      <td>541909</td>\n",
       "      <td>541909</td>\n",
       "      <td>541909</td>\n",
       "      <td>541909</td>\n",
       "      <td>541909</td>\n",
       "      <td>541909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>559965.752026781</td>\n",
       "      <td>27623.240210938104</td>\n",
       "      <td>14.23573883161512</td>\n",
       "      <td>9.55224954743324</td>\n",
       "      <td>None</td>\n",
       "      <td>29.921163668665333</td>\n",
       "      <td>11476.974671024102</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>13428.417280805148</td>\n",
       "      <td>16799.73762842771</td>\n",
       "      <td>543.0146023996443</td>\n",
       "      <td>218.08115785023355</td>\n",
       "      <td>None</td>\n",
       "      <td>595.7455525989111</td>\n",
       "      <td>6777.908326012993</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>536365</td>\n",
       "      <td>10002</td>\n",
       "      <td>\"ASSORTED FLOWER COLOUR \"\"LEIS\"\"\"</td>\n",
       "      <td>-80995</td>\n",
       "      <td>1.02.2011 08:23</td>\n",
       "      <td>-11062,06</td>\n",
       "      <td>0</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>C581569</td>\n",
       "      <td>m</td>\n",
       "      <td>wrongly sold sets</td>\n",
       "      <td>80995</td>\n",
       "      <td>9.12.2011 12:50</td>\n",
       "      <td>99,96</td>\n",
       "      <td>18287</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary           InvoiceNo           StockCode  \\\n",
       "0   count              541909              541909   \n",
       "1    mean    559965.752026781  27623.240210938104   \n",
       "2  stddev  13428.417280805148   16799.73762842771   \n",
       "3     min              536365               10002   \n",
       "4     max             C581569                   m   \n",
       "\n",
       "                         Description            Quantity      InvoiceDate  \\\n",
       "0                             541909              541909           541909   \n",
       "1                  14.23573883161512    9.55224954743324             None   \n",
       "2                  543.0146023996443  218.08115785023355             None   \n",
       "3  \"ASSORTED FLOWER COLOUR \"\"LEIS\"\"\"              -80995  1.02.2011 08:23   \n",
       "4                  wrongly sold sets               80995  9.12.2011 12:50   \n",
       "\n",
       "            UnitPrice          CustomerID      Country  \n",
       "0              541909              541909       541909  \n",
       "1  29.921163668665333  11476.974671024102         None  \n",
       "2   595.7455525989111   6777.908326012993         None  \n",
       "3           -11062,06                   0    Australia  \n",
       "4               99,96               18287  Unspecified  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b6790c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "74712e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|   541909|   541909|     541909|  541909|     541909|   541909|    541909| 541909|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "def my_count(df_in):\n",
    "    df_in.agg(*[count(c).alias(c) for c in df_in.columns]).show()\n",
    "my_count(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f0115b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|    InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|1.12.2010 08:26|     2,55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|1.12.2010 08:26|     2,75|     17850|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|1.12.2010 08:26|     7,65|     17850|United Kingdom|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|1.12.2010 08:26|     4,25|     17850|United Kingdom|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|1.12.2010 08:28|     1,85|     17850|United Kingdom|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|1.12.2010 08:28|     1,85|     17850|United Kingdom|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|1.12.2010 08:34|     1,69|     13047|United Kingdom|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|1.12.2010 08:34|      2,1|     13047|United Kingdom|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|1.12.2010 08:34|      2,1|     13047|United Kingdom|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|1.12.2010 08:34|     3,75|     13047|United Kingdom|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|1.12.2010 08:34|     1,65|     13047|United Kingdom|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|1.12.2010 08:34|     4,25|     13047|United Kingdom|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|1.12.2010 08:34|     4,95|     13047|United Kingdom|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|1.12.2010 08:34|     9,95|     13047|United Kingdom|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|1.12.2010 08:34|     5,95|     13047|United Kingdom|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|1.12.2010 08:34|     5,95|     13047|United Kingdom|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|1.12.2010 08:34|     7,95|     13047|United Kingdom|\n",
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a82ea60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+-------------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|    InvoiceDate|UnitPrice|CustomerID|       Country|    NewInvoiceData2|\n",
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+-------------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|1.12.2010 08:26|     2,55|     17850|United Kingdom|2010-12-01 08:26:00|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|2010-12-01 08:26:00|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|1.12.2010 08:26|     2,75|     17850|United Kingdom|2010-12-01 08:26:00|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|2010-12-01 08:26:00|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|2010-12-01 08:26:00|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|1.12.2010 08:26|     7,65|     17850|United Kingdom|2010-12-01 08:26:00|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|1.12.2010 08:26|     4,25|     17850|United Kingdom|2010-12-01 08:26:00|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|1.12.2010 08:28|     1,85|     17850|United Kingdom|2010-12-01 08:28:00|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|1.12.2010 08:28|     1,85|     17850|United Kingdom|2010-12-01 08:28:00|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|1.12.2010 08:34|     1,69|     13047|United Kingdom|2010-12-01 08:34:00|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|1.12.2010 08:34|      2,1|     13047|United Kingdom|2010-12-01 08:34:00|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|1.12.2010 08:34|      2,1|     13047|United Kingdom|2010-12-01 08:34:00|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|1.12.2010 08:34|     3,75|     13047|United Kingdom|2010-12-01 08:34:00|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|1.12.2010 08:34|     1,65|     13047|United Kingdom|2010-12-01 08:34:00|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|1.12.2010 08:34|     4,25|     13047|United Kingdom|2010-12-01 08:34:00|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|1.12.2010 08:34|     4,95|     13047|United Kingdom|2010-12-01 08:34:00|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|1.12.2010 08:34|     9,95|     13047|United Kingdom|2010-12-01 08:34:00|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|1.12.2010 08:34|     5,95|     13047|United Kingdom|2010-12-01 08:34:00|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|1.12.2010 08:34|     5,95|     13047|United Kingdom|2010-12-01 08:34:00|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|1.12.2010 08:34|     7,95|     13047|United Kingdom|2010-12-01 08:34:00|\n",
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "timeFmt = \"MM/dd/yy HH:mm\"\n",
    "df = df.withColumn(\"NewInvoiceData2\",  to_timestamp(\"InvoiceDate\",\"d.MM.yyyy HH:mm\"))\n",
    "df.show()\n",
    "# df = df.withColumn('NewInvoiceDate', when(col('InvoiceDate').isNotNull(), to_utc_timestamp(unix_timestamp(col('InvoiceDate'), timeFmt).cast('timestamp'), 'UTC')).otherwise(col('InvoiceDate')))\n",
    "\n",
    "# df.show(5)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "50d0f28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+-------------------+----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|    InvoiceDate|UnitPrice|CustomerID|       Country|    NewInvoiceData2|TotalPrice|\n",
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+-------------------+----------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|1.12.2010 08:26|     2.55|     17850|United Kingdom|2010-12-01 08:26:00|      15.3|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|1.12.2010 08:26|     3.39|     17850|United Kingdom|2010-12-01 08:26:00|     20.34|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|1.12.2010 08:26|     2.75|     17850|United Kingdom|2010-12-01 08:26:00|      22.0|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|1.12.2010 08:26|     3.39|     17850|United Kingdom|2010-12-01 08:26:00|     20.34|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|1.12.2010 08:26|     3.39|     17850|United Kingdom|2010-12-01 08:26:00|     20.34|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|1.12.2010 08:26|     7.65|     17850|United Kingdom|2010-12-01 08:26:00|      15.3|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|1.12.2010 08:26|     4.25|     17850|United Kingdom|2010-12-01 08:26:00|      25.5|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|1.12.2010 08:28|     1.85|     17850|United Kingdom|2010-12-01 08:28:00|      11.1|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|1.12.2010 08:28|     1.85|     17850|United Kingdom|2010-12-01 08:28:00|      11.1|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|1.12.2010 08:34|     1.69|     13047|United Kingdom|2010-12-01 08:34:00|     54.08|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|1.12.2010 08:34|      2.1|     13047|United Kingdom|2010-12-01 08:34:00|      12.6|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|1.12.2010 08:34|      2.1|     13047|United Kingdom|2010-12-01 08:34:00|      12.6|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|1.12.2010 08:34|     3.75|     13047|United Kingdom|2010-12-01 08:34:00|      30.0|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|1.12.2010 08:34|     1.65|     13047|United Kingdom|2010-12-01 08:34:00|       9.9|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|1.12.2010 08:34|     4.25|     13047|United Kingdom|2010-12-01 08:34:00|      25.5|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|1.12.2010 08:34|     4.95|     13047|United Kingdom|2010-12-01 08:34:00|     14.85|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|1.12.2010 08:34|     9.95|     13047|United Kingdom|2010-12-01 08:34:00|      19.9|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|1.12.2010 08:34|     5.95|     13047|United Kingdom|2010-12-01 08:34:00|     17.85|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|1.12.2010 08:34|     5.95|     13047|United Kingdom|2010-12-01 08:34:00|     17.85|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|1.12.2010 08:34|     7.95|     13047|United Kingdom|2010-12-01 08:34:00|      31.8|\n",
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = df.withColumn(\"UnitPrice\", F.regexp_replace(\"UnitPrice\", \",\", \".\").cast(\"double\"))\n",
    "\n",
    "df = df.withColumn('TotalPrice', round(df.Quantity * df.UnitPrice, 2) )\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33a9072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_utc_timestamp,unix_timestamp,lit,datediff,col\n",
    "from pyspark.sql.functions import date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a5c6e541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+-------------------+----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|    InvoiceDate|UnitPrice|CustomerID|       Country|    NewInvoiceData2|TotalPrice|\n",
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+-------------------+----------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|1.12.2010 08:26|     2.55|     17850|United Kingdom|2010-12-01 08:26:00|      15.3|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|1.12.2010 08:26|     3.39|     17850|United Kingdom|2010-12-01 08:26:00|     20.34|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|1.12.2010 08:26|     2.75|     17850|United Kingdom|2010-12-01 08:26:00|      22.0|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|1.12.2010 08:26|     3.39|     17850|United Kingdom|2010-12-01 08:26:00|     20.34|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|1.12.2010 08:26|     3.39|     17850|United Kingdom|2010-12-01 08:26:00|     20.34|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|1.12.2010 08:26|     7.65|     17850|United Kingdom|2010-12-01 08:26:00|      15.3|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|1.12.2010 08:26|     4.25|     17850|United Kingdom|2010-12-01 08:26:00|      25.5|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|1.12.2010 08:28|     1.85|     17850|United Kingdom|2010-12-01 08:28:00|      11.1|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|1.12.2010 08:28|     1.85|     17850|United Kingdom|2010-12-01 08:28:00|      11.1|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|1.12.2010 08:34|     1.69|     13047|United Kingdom|2010-12-01 08:34:00|     54.08|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|1.12.2010 08:34|      2.1|     13047|United Kingdom|2010-12-01 08:34:00|      12.6|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|1.12.2010 08:34|      2.1|     13047|United Kingdom|2010-12-01 08:34:00|      12.6|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|1.12.2010 08:34|     3.75|     13047|United Kingdom|2010-12-01 08:34:00|      30.0|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|1.12.2010 08:34|     1.65|     13047|United Kingdom|2010-12-01 08:34:00|       9.9|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|1.12.2010 08:34|     4.25|     13047|United Kingdom|2010-12-01 08:34:00|      25.5|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|1.12.2010 08:34|     4.95|     13047|United Kingdom|2010-12-01 08:34:00|     14.85|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|1.12.2010 08:34|     9.95|     13047|United Kingdom|2010-12-01 08:34:00|      19.9|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|1.12.2010 08:34|     5.95|     13047|United Kingdom|2010-12-01 08:34:00|     17.85|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|1.12.2010 08:34|     5.95|     13047|United Kingdom|2010-12-01 08:34:00|     17.85|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|1.12.2010 08:34|     7.95|     13047|United Kingdom|2010-12-01 08:34:00|      31.8|\n",
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "60e737c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '`NewInvoiceDate2`' given input columns: [Country, CustomerID, Description, InvoiceDate, InvoiceNo, NewInvoiceData2, Quantity, StockCode, TotalPrice, UnitPrice];;\n'Aggregate [max('NewInvoiceDate2) AS max(NewInvoiceDate2)#4497]\n+- Project [InvoiceNo#3382, StockCode#3383, Description#3384, Quantity#3385, InvoiceDate#3386, UnitPrice#4122, CustomerID#3388, Country#3389, NewInvoiceData2#4050, round((cast(Quantity#3385 as double) * UnitPrice#4122), 2) AS TotalPrice#4132]\n   +- Project [InvoiceNo#3382, StockCode#3383, Description#3384, Quantity#3385, InvoiceDate#3386, cast(regexp_replace(UnitPrice#3387, ,, .) as double) AS UnitPrice#4122, CustomerID#3388, Country#3389, NewInvoiceData2#4050]\n      +- Project [InvoiceNo#3382, StockCode#3383, Description#3384, Quantity#3385, InvoiceDate#3386, UnitPrice#3387, CustomerID#3388, Country#3389, to_timestamp('InvoiceDate, Some(d.MM.yyyy HH:mm)) AS NewInvoiceData2#4050]\n         +- RelationV2[InvoiceNo#3382, StockCode#3383, Description#3384, Quantity#3385, InvoiceDate#3386, UnitPrice#3387, CustomerID#3388, Country#3389] csv file:/C:/Users/brhng/Desktop/OnlineRetail.csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.8.1-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o537.select.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`NewInvoiceDate2`' given input columns: [Country, CustomerID, Description, InvoiceDate, InvoiceNo, NewInvoiceData2, Quantity, StockCode, TotalPrice, UnitPrice];;\n'Aggregate [max('NewInvoiceDate2) AS max(NewInvoiceDate2)#4497]\n+- Project [InvoiceNo#3382, StockCode#3383, Description#3384, Quantity#3385, InvoiceDate#3386, UnitPrice#4122, CustomerID#3388, Country#3389, NewInvoiceData2#4050, round((cast(Quantity#3385 as double) * UnitPrice#4122), 2) AS TotalPrice#4132]\n   +- Project [InvoiceNo#3382, StockCode#3383, Description#3384, Quantity#3385, InvoiceDate#3386, cast(regexp_replace(UnitPrice#3387, ,, .) as double) AS UnitPrice#4122, CustomerID#3388, Country#3389, NewInvoiceData2#4050]\n      +- Project [InvoiceNo#3382, StockCode#3383, Description#3384, Quantity#3385, InvoiceDate#3386, UnitPrice#3387, CustomerID#3388, Country#3389, to_timestamp('InvoiceDate, Some(d.MM.yyyy HH:mm)) AS NewInvoiceData2#4050]\n         +- RelationV2[InvoiceNo#3382, StockCode#3383, Description#3384, Quantity#3385, InvoiceDate#3386, UnitPrice#3387, CustomerID#3388, Country#3389] csv file:/C:/Users/brhng/Desktop/OnlineRetail.csv\n\r\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:140)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:137)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$2(TreeNode.scala:310)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:310)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$1(TreeNode.scala:307)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:376)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:214)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:374)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:327)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:307)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$1(TreeNode.scala:307)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:376)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:214)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:374)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:327)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:307)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$1(TreeNode.scala:307)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:376)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:214)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:374)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:327)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:307)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsUp$1(QueryPlan.scala:97)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:109)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:109)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:120)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$3(QueryPlan.scala:125)\r\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\r\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\r\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:125)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:130)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:214)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:130)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:97)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:137)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:91)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:154)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:91)\r\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:88)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:122)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:148)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:145)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:69)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:66)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:66)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:58)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:87)\r\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3501)\r\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1430)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2160/52097396.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatediff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdate_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NewInvoiceDate2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_utc_timestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munix_timestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate_max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'yy-MM-dd HH:mm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'UTC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[1;34m(self, *cols)\u001b[0m\n\u001b[0;32m   1368\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mu'Alice'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mu'Bob'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \"\"\"\n\u001b[1;32m-> 1370\u001b[1;33m         \u001b[0mjdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.8.1-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1286\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnknownException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: cannot resolve '`NewInvoiceDate2`' given input columns: [Country, CustomerID, Description, InvoiceDate, InvoiceNo, NewInvoiceData2, Quantity, StockCode, TotalPrice, UnitPrice];;\n'Aggregate [max('NewInvoiceDate2) AS max(NewInvoiceDate2)#4497]\n+- Project [InvoiceNo#3382, StockCode#3383, Description#3384, Quantity#3385, InvoiceDate#3386, UnitPrice#4122, CustomerID#3388, Country#3389, NewInvoiceData2#4050, round((cast(Quantity#3385 as double) * UnitPrice#4122), 2) AS TotalPrice#4132]\n   +- Project [InvoiceNo#3382, StockCode#3383, Description#3384, Quantity#3385, InvoiceDate#3386, cast(regexp_replace(UnitPrice#3387, ,, .) as double) AS UnitPrice#4122, CustomerID#3388, Country#3389, NewInvoiceData2#4050]\n      +- Project [InvoiceNo#3382, StockCode#3383, Description#3384, Quantity#3385, InvoiceDate#3386, UnitPrice#3387, CustomerID#3388, Country#3389, to_timestamp('InvoiceDate, Some(d.MM.yyyy HH:mm)) AS NewInvoiceData2#4050]\n         +- RelationV2[InvoiceNo#3382, StockCode#3383, Description#3384, Quantity#3385, InvoiceDate#3386, UnitPrice#3387, CustomerID#3388, Country#3389] csv file:/C:/Users/brhng/Desktop/OnlineRetail.csv\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "\n",
    "from pyspark.sql.functions import mean, min, max, sum, datediff, to_date\n",
    "\n",
    "date_max = df.select(max('NewInvoiceDate2')).toPandas()\n",
    "\n",
    "current = to_utc_timestamp(unix_timestamp(lit(str(date_max.iloc[0][0])), 'yy-MM-dd HH:mm').cast('timestamp'), 'UTC')\n",
    "\n",
    "df = df.withColumn('Duration', datediff(lit(current), 'NewInvoiceDate'))\n",
    "\n",
    "#Recency, Frequency, Monetary\n",
    "\n",
    "recency = df.groupBy('CustomerID').agg(min('Duration').alias('Recency'))\n",
    "\n",
    "frequency = df.groupBy('CustomerID', 'InvoiceNo').count()\\\n",
    "    .groupBy('CustomerID')\\\n",
    "    .agg(count('*').alias(\"Frequency\"))\n",
    "\n",
    "monetary = df.groupBy('CustomerID').agg(round(sum('TotalPrice'), 2).alias('Monetary'))\n",
    "\n",
    "rfm = recency.join(frequency, 'CustomerID', how = 'inner')\\\n",
    "    .join(monetary, 'CustomerID', how = 'inner')\n",
    "\n",
    "rfm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "526d172b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'LOW'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2160/614777981.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TotalPrice'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQuantity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDoubleType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLOW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1347\u001b[0m         \"\"\"\n\u001b[0;32m   1348\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m             raise AttributeError(\n\u001b[0m\u001b[0;32m   1350\u001b[0m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0;32m   1351\u001b[0m         \u001b[0mjc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'LOW'"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('TotalPrice', round(df.Quantity.cast(DoubleType()) * df.LOW), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "332a181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('UnitPrice2',df.UnitPrice.cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a61b18e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|    InvoiceDate|UnitPrice|CustomerID|       Country|UnitPrice2|\n",
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+----------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|1.12.2010 08:26|     2,55|     17850|United Kingdom|      null|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|      null|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|1.12.2010 08:26|     2,75|     17850|United Kingdom|      null|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|      null|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|      null|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|1.12.2010 08:26|     7,65|     17850|United Kingdom|      null|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|1.12.2010 08:26|     4,25|     17850|United Kingdom|      null|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|1.12.2010 08:28|     1,85|     17850|United Kingdom|      null|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|1.12.2010 08:28|     1,85|     17850|United Kingdom|      null|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|1.12.2010 08:34|     1,69|     13047|United Kingdom|      null|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|1.12.2010 08:34|      2,1|     13047|United Kingdom|      null|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|1.12.2010 08:34|      2,1|     13047|United Kingdom|      null|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|1.12.2010 08:34|     3,75|     13047|United Kingdom|      null|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|1.12.2010 08:34|     1,65|     13047|United Kingdom|      null|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|1.12.2010 08:34|     4,25|     13047|United Kingdom|      null|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|1.12.2010 08:34|     4,95|     13047|United Kingdom|      null|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|1.12.2010 08:34|     9,95|     13047|United Kingdom|      null|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|1.12.2010 08:34|     5,95|     13047|United Kingdom|      null|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|1.12.2010 08:34|     5,95|     13047|United Kingdom|      null|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|1.12.2010 08:34|     7,95|     13047|United Kingdom|      null|\n",
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "df.withColumn(\"UnitPrice2\",col(\"UnitPrice\").cast(DoubleType())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "38c6630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df3 = df.withColumn(\"LOW\", F.regexp_replace(\"UnitPrice\", \",\", \".\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5b140ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('InvoiceNo', 'string'),\n",
       " ('StockCode', 'string'),\n",
       " ('Description', 'string'),\n",
       " ('Quantity', 'int'),\n",
       " ('InvoiceDate', 'string'),\n",
       " ('UnitPrice', 'double'),\n",
       " ('CustomerID', 'int'),\n",
       " ('Country', 'string'),\n",
       " ('NewInvoiceData2', 'timestamp'),\n",
       " ('TotalPrice', 'double')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "faa94606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_pd(df_in, columns, style):\n",
    "    '''\n",
    "    Function to union the basic stats results and deciles\n",
    "    :param df_in: the input dataframe \n",
    "    :param columns: the cloumn name list of the numerical variable     \n",
    "    :param style: the display style  \n",
    "\n",
    "    :return : the numerical describe info. of the input dataframe   \n",
    "\n",
    "    :author: Wenqiang Feng\n",
    "    :email:  von198@gmail.com  \n",
    "    '''       \n",
    "\n",
    "    if style == 1:\n",
    "        percentiles = [25, 50, 75]\n",
    "    else:\n",
    "        percentiles = np.array(range(0, 110, 10))\n",
    "    \n",
    "    percs = np.transpose([np.percentile(df_in.select(x).collect(), percentiles) for x in columns])\n",
    "    percs = pd.DataFrame(percs, columns=columns)\n",
    "    percs['summary'] = [str(p) + '%' for p in percentiles]\n",
    "    \n",
    "    spark_describe = df_in.describe().toPandas()\n",
    "    new_df = pd.concat([spark_describe, percs],ignore_index=True)\n",
    "    new_df = new_df.round(2)\n",
    "    return new_df[['summary'] + columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b679e67f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2160/1765764521.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'rdd' is not defined"
     ]
    }
   ],
   "source": [
    "rdd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80934f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
