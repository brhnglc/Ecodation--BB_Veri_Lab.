{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54a8bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.types import StructType , StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06702a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in c:\\users\\brhng\\anaconda3\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType , StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71166ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"giveatry\").getOrCreate()\n",
    "\n",
    "data = [(\"James\",\"\",\"William\",\"36636\",\"M\",3000),(\"Micheal\",\"Smith\",\"\",\"40288\",\"M\",4000),(\"Robert\",\"\",\"Dawson\",\"42114\",\"M\",4000),\n",
    "        (\"Maria\",\"\",\"Jones\",\"39192\",\"F\",4000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd7f0783",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\\\n",
    "    StructField(\"firstname\",StringType(),True),\\\n",
    "    StructField(\"middlename\",StringType(),True),\\\n",
    "    StructField(\"lastname\",StringType(),True),\n",
    "    StructField(\"id\",StringType(),True),\\\n",
    "    StructField(\"gender\",StringType(),True),\\\n",
    "    StructField(\"salary\",IntegerType(),True)]    \n",
    ")\n",
    "#null olup olmama durumu true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1593cdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|id   |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|James    |          |William |36636|M     |3000  |\n",
      "|Micheal  |Smith     |        |40288|M     |4000  |\n",
      "|Robert   |          |Dawson  |42114|M     |4000  |\n",
      "|Maria    |          |Jones   |39192|F     |4000  |\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3008591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+-------------+----------+------+\n",
      "|Employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|James        |Sales     |3000  |\n",
      "|Micheal      |Sales     |4600  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Maria        |Finance   |3000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Scoot        |Finance   |3300  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|Dogu         |Sales     |4100  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"giveatry2\").getOrCreate()\n",
    "\n",
    "data = [(\"James\",\"Sales\",3000),[\"Micheal\",\"Sales\",4600],(\"Robert\",\"Sales\",4100),(\"Maria\",\"Finance\",3000),(\"James\",\"Sales\",3000),(\"Scoot\",\"Finance\",3300),(\"Jen\",\"Finance\",3900),(\"Jeff\",\"Marketing\",3000),(\"Kumar\",\"Marketing\",2000),(\"Dogu\",\"Sales\",4100)]\n",
    "column = [\"Employee_name\",\"department\",\"salary\"]\n",
    "df = spark.createDataFrame(data=data,schema=column)\n",
    "df.printSchema()\n",
    "df.show(truncate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9c7e505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disctinct count:9\n",
      "+-------------+----------+------+\n",
      "|Employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|Micheal      |Sales     |4600  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|Scoot        |Finance   |3300  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "|Maria        |Finance   |3000  |\n",
      "|Dogu         |Sales     |4100  |\n",
      "+-------------+----------+------+\n",
      "\n",
      "Disctinct count:9\n",
      "+-------------+----------+------+\n",
      "|Employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|Micheal      |Sales     |4600  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|Scoot        |Finance   |3300  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "|Maria        |Finance   |3000  |\n",
      "|Dogu         |Sales     |4100  |\n",
      "+-------------+----------+------+\n",
      "\n",
      "Disctinct count:8\n",
      "+-------------+----------+------+\n",
      "|Employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|Micheal      |Sales     |4600  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|Maria        |Finance   |3000  |\n",
      "|Scoot        |Finance   |3300  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Distinct\n",
    "distincDF = df.distinct()\n",
    "print(\"Disctinct count:\"+str(distincDF.count()))\n",
    "distincDF.show(truncate= False)\n",
    "\n",
    "#Drop Duplicates\n",
    "df2 = df.dropDuplicates()\n",
    "print(\"Disctinct count:\"+str(df2.count()))\n",
    "df2.show(truncate= False)\n",
    "\n",
    "#Drop Duplicates with particualar columns\n",
    "dropDisDF = df.dropDuplicates([\"department\",\"salary\"]) # ikisnin de aynı olanlar duplicate sayılıcak\n",
    "print(\"Disctinct count:\"+str(dropDisDF.count()))\n",
    "dropDisDF.show(truncate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e92ee4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Employee_name department  salary\n",
      "0         James      Sales    3000\n",
      "1       Micheal      Sales    4600\n",
      "2        Robert      Sales    4100\n",
      "3         Maria    Finance    3000\n",
      "4         James      Sales    3000\n",
      "5         Scoot    Finance    3300\n",
      "6           Jen    Finance    3900\n",
      "7          Jeff  Marketing    3000\n",
      "8         Kumar  Marketing    2000\n",
      "9          Dogu      Sales    4100\n"
     ]
    }
   ],
   "source": [
    "PandasDF = df.toPandas()\n",
    "print(PandasDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8774053f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Amount: long (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+-------+------+-------+\n",
      "|Product|Amount|Country|\n",
      "+-------+------+-------+\n",
      "|Banana |1000  |USA    |\n",
      "|Carrots|1500  |USA    |\n",
      "|Beans  |1600  |USA    |\n",
      "|Orange |2000  |USA    |\n",
      "|Orange |2000  |USA    |\n",
      "|Banana |4000  |China  |\n",
      "|Carrots|1200  |China  |\n",
      "|Beans  |1500  |China  |\n",
      "|Orange |4000  |China  |\n",
      "|Banana |2000  |Canada |\n",
      "|Carrots|2000  |Canada |\n",
      "|Beans  |2000  |Mexico |\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"Banana\", 1000, \"USA\"), (\"Carrots\", 1500, \"USA\"), (\"Beans\", 1600, \"USA\"),(\"Orange\", 2000, \"USA\"), (\"Orange\", 2000, \"USA\"), (\"Banana\", 4000, \"China\"),(\"Carrots\", 1200, \"China\"), (\"Beans\", 1500, \"China\"), (\"Orange\", 4000, \"China\"),(\"Banana\", 2000, \"Canada\"), (\"Carrots\", 2000, \"Canada\"), (\"Beans\", 2000, \"Mexico\")]\n",
    "columns = [\"Product\",\"Amount\",\"Country\"]\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=columns)\n",
    "df.printSchema()\n",
    "df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "465773cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Canada: long (nullable = true)\n",
      " |-- China: long (nullable = true)\n",
      " |-- Mexico: long (nullable = true)\n",
      " |-- USA: long (nullable = true)\n",
      "\n",
      "+-------+------+-----+------+----+\n",
      "|Product|Canada|China|Mexico|USA |\n",
      "+-------+------+-----+------+----+\n",
      "|Orange |null  |4000 |null  |4000|\n",
      "|Beans  |null  |1500 |2000  |1600|\n",
      "|Banana |2000  |4000 |null  |1000|\n",
      "|Carrots|2000  |1200 |null  |1500|\n",
      "+-------+------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pivot sabit demek basketballdaki gibi bir sutünü sabit tutup diyerlerini\n",
    "pivotDf = df.groupby(\"Product\").pivot(\"Country\").sum(\"Amount\")\n",
    "pivotDf.printSchema()\n",
    "pivotDf.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9047b753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- TV: double (nullable = true)\n",
      " |-- Radio: double (nullable = true)\n",
      " |-- Newspaper: double (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n",
      "+---+-----+-----+---------+-----+\n",
      "|_c0|   TV|Radio|Newspaper|Sales|\n",
      "+---+-----+-----+---------+-----+\n",
      "|  1|230.1| 37.8|     69.2| 22.1|\n",
      "|  2| 44.5| 39.3|     45.1| 10.4|\n",
      "|  3| 17.2| 45.9|     69.3|  9.3|\n",
      "|  4|151.5| 41.3|     58.5| 18.5|\n",
      "|  5|180.8| 10.8|     58.4| 12.9|\n",
      "+---+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dışarıdan veri ile çalışma\n",
    "#df = spark.read.format('delta').options(header =\"True\",inferschema=\"True\").load(\"C:\\\\Users\\\\brhng\\\\Desktop\\\\Advertising.csv\")\n",
    "df = spark.read.format('delta').options(header=\"True\",inferschema=\"True\").csv(\"C:\\\\Users\\\\brhng\\\\Desktop\\\\Advertising.csv\")\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79c4248f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----+\n",
      "|col1|col2|col3| col4|\n",
      "+----+----+----+-----+\n",
      "|   1|   2|   3|a b c|\n",
      "|   4|   5|   6|d e f|\n",
      "|   7|   8|   9|g h i|\n",
      "+----+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RDD creation\n",
    "df = spark.sparkContext.parallelize([(1,2,3,\"a b c\"),(4,5,6,\"d e f\"),(7,8,9,\"g h i\")]).toDF([\"col1\",\"col2\",\"col3\",\"col4\"])\n",
    "df.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474a5e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
